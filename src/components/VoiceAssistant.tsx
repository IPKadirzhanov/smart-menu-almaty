"use client";

import React, { useState, useCallback, useRef } from 'react';
import { useConversation } from '@elevenlabs/react';
import { Mic, MicOff, Volume2, Loader2, Bug } from 'lucide-react';
import { motion, AnimatePresence } from 'framer-motion';
import { supabase } from '@/integrations/supabase/client';
import { extractUIAction } from '@/lib/uiAction';
import MenuPickerModal, { MenuPickerPayload } from '@/components/MenuPickerModal';
import { menuItems, categoryLabels } from '@/data/menu';

function buildMenuContext(): string {
  const grouped: Record<string, string[]> = {};
  menuItems.forEach(item => {
    const cat = categoryLabels[item.category] || item.category;
    if (!grouped[cat]) grouped[cat] = [];
    grouped[cat].push(`${item.name} (id:${item.id}, ${item.priceKZT}‚Ç∏)`);
  });
  const lines = Object.entries(grouped).map(([cat, items]) => `${cat}: ${items.join(', ')}`).join('\n');

  return `–¢—ã ‚Äî –≥–æ–ª–æ—Å–æ–≤–æ–π –ø–æ–º–æ—â–Ω–∏–∫ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞ SmartMenu –≤ –ê–ª–º–∞—Ç—ã. –ü–æ–º–æ–≥–∞–µ—à—å –≥–æ—Å—Ç—è–º –ø–æ–¥–æ–±—Ä–∞—Ç—å –∑–∞–∫–∞–∑ –ø–æ –±—é–¥–∂–µ—Ç—É –∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º.

–ú–ï–ù–Æ –†–ï–°–¢–û–†–ê–ù–ê:
${lines}

–í–ê–ñ–ù–û: –ö–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –ø–æ–¥–æ–±—Ä–∞—Ç—å –º–µ–Ω—é (—É–∫–∞–∑—ã–≤–∞–µ—Ç –±—é–¥–∂–µ—Ç, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª—é–¥–µ–π, –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è), —Ç—ã –î–û–õ–ñ–ï–ù –≤ —Å–≤–æ—ë–º –æ—Ç–≤–µ—Ç–µ –≤–∫–ª—é—á–∏—Ç—å –±–ª–æ–∫:

<UI_ACTION>
{
  "action": "OPEN_MENU_PICKER",
  "title": "–ü–æ–¥–±–æ—Ä –º–µ–Ω—é –Ω–∞ [–±—é–¥–∂–µ—Ç] –¥–ª—è [–∫–æ–ª-–≤–æ] —á–µ–ª–æ–≤–µ–∫",
  "variants": [
    {
      "name": "–í–∞—Ä–∏–∞–Ω—Ç A ‚Äî –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π",
      "items": [{"id": "h1", "name": "–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –∫–∞–ª—å—è–Ω", "price": 7000}, ...],
      "total": 25000
    },
    {
      "name": "–í–∞—Ä–∏–∞–Ω—Ç B ‚Äî –°—ã—Ç–Ω—ã–π",
      "items": [...],
      "total": 28000
    },
    {
      "name": "–í–∞—Ä–∏–∞–Ω—Ç C ‚Äî –õ—ë–≥–∫–∏–π",
      "items": [...],
      "total": 22000
    }
  ]
}
</UI_ACTION>

–ü—Ä–∞–≤–∏–ª–∞ –ø–æ–¥–±–æ—Ä–∞:
- –°–æ–∑–¥–∞–≤–∞–π —Ä–æ–≤–Ω–æ 3 –≤–∞—Ä–∏–∞–Ω—Ç–∞ (–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –°—ã—Ç–Ω—ã–π, –õ—ë–≥–∫–∏–π)
- –ò—Ç–æ–≥–æ –∫–∞–∂–¥–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 80-100% –æ—Ç –±—é–¥–∂–µ—Ç–∞
- –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û id –∏–∑ –º–µ–Ω—é –≤—ã—à–µ
- –£—á–∏—Ç—ã–≤–∞–π –ø–æ–∂–µ–ª–∞–Ω–∏—è (—Ö–∞–ª—è–ª—å, –±–µ–∑ –∞–ª–∫–æ–≥–æ–ª—è, –≤–µ–≥–∞–Ω –∏ —Ç.–¥.)
- –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- –ë–ª–æ–∫ <UI_ACTION> –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç–∫—Ä–æ–µ—Ç –º–æ–¥–∞–ª–∫—É –≤—ã–±–æ—Ä–∞ –Ω–∞ —ç–∫—Ä–∞–Ω–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è`;
}

interface DebugInfo {
  signedUrl: 'pending' | 'OK' | 'FAIL';
  token: 'pending' | 'OK' | 'FAIL';
  micPermission: 'pending' | 'granted' | 'denied';
  connectionType: string;
  session: 'idle' | 'starting' | 'started' | 'failed';
  lastError: string;
  lastEventType: string;
  audioTracksCount: number;
}

const VoiceAssistant: React.FC = () => {
  const [isConnecting, setIsConnecting] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [agentText, setAgentText] = useState('');
  const [error, setError] = useState('');
  const [pickerPayload, setPickerPayload] = useState<MenuPickerPayload | null>(null);
  const [showDebug, setShowDebug] = useState(false);
  const contextSent = useRef(false);

  const [debug, setDebug] = useState<DebugInfo>({
    signedUrl: 'pending',
    token: 'pending',
    micPermission: 'pending',
    connectionType: 'webrtc',
    session: 'idle',
    lastError: '',
    lastEventType: '',
    audioTracksCount: 0,
  });

  const updateDebug = useCallback((partial: Partial<DebugInfo>) => {
    setDebug(prev => ({ ...prev, ...partial }));
  }, []);

  const processAgentResponse = useCallback((text: string) => {
    setAgentText(text);
    const action = extractUIAction(text);
    if (action && action.action === 'OPEN_MENU_PICKER') {
      setPickerPayload({
        title: action.title || '–ü–æ–¥–æ–±—Ä–∞–Ω–Ω–æ–µ –º–µ–Ω—é',
        variants: action.variants || [],
      });
    }
  }, []);

  const conversation = useConversation({
    onConnect: () => {
      console.log('[ElevenLabs] Connected');
      setError('');
      updateDebug({ session: 'started', lastEventType: 'connected' });
    },
    onDisconnect: () => {
      console.log('[ElevenLabs] Disconnected');
      contextSent.current = false;
      updateDebug({ session: 'idle', lastEventType: 'disconnected' });
    },
    onError: (err) => {
      console.error('[ElevenLabs] Error:', err);
      const msg = typeof err === 'string' ? err : (err as any)?.message || String(err);
      setError(msg);
      updateDebug({ lastError: msg, lastEventType: 'error' });
    },
    onMessage: (message: any) => {
      console.log('[ElevenLabs] Message:', message.type, message);
      updateDebug({ lastEventType: message.type });

      if (message.type === 'user_transcript') {
        const text = message.user_transcription_event?.user_transcript || '';
        setTranscript(text);
      }
      if (message.type === 'agent_response') {
        const response = message.agent_response_event?.agent_response || '';
        processAgentResponse(response);
      }
    },
  });

  const start = useCallback(async () => {
    setIsConnecting(true);
    setError('');
    updateDebug({ session: 'starting', lastError: '', signedUrl: 'pending', token: 'pending', micPermission: 'pending' });

    try {
      // 1. Request microphone
      console.log('[ElevenLabs] Requesting microphone...');
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        updateDebug({ micPermission: 'granted', audioTracksCount: stream.getAudioTracks().length });
        console.log('[ElevenLabs] Mic granted, tracks:', stream.getAudioTracks().length);
        // Stop tracks - the SDK will request its own
        stream.getTracks().forEach(t => t.stop());
      } catch (micErr: any) {
        updateDebug({ micPermission: 'denied', lastError: micErr.message });
        throw new Error('–ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω: ' + micErr.message);
      }

      // 2. Get credentials from edge function
      console.log('[ElevenLabs] Fetching credentials...');
      const { data, error: fnError } = await supabase.functions.invoke('elevenlabs-signed-url');
      console.log('[ElevenLabs] Credentials response:', data, fnError);

      if (fnError || !data) {
        updateDebug({ signedUrl: 'FAIL', token: 'FAIL', lastError: fnError?.message || 'No data' });
        throw new Error(fnError?.message || '–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å credentials');
      }

      const hasToken = !!data.token;
      const hasSignedUrl = !!data.signed_url;
      updateDebug({
        token: hasToken ? 'OK' : 'FAIL',
        signedUrl: hasSignedUrl ? 'OK' : 'FAIL',
      });

      // 3. Start session - prefer WebRTC (token), fallback to WebSocket (signed_url)
      if (hasToken) {
        console.log('[ElevenLabs] Starting WebRTC session with token...');
        updateDebug({ connectionType: 'webrtc' });
        await conversation.startSession({
          conversationToken: data.token,
          connectionType: 'webrtc',
        } as any);
      } else if (hasSignedUrl) {
        console.log('[ElevenLabs] Falling back to WebSocket with signed_url...');
        updateDebug({ connectionType: 'websocket' });
        await conversation.startSession({
          signedUrl: data.signed_url,
        });
      } else {
        throw new Error('–ù–µ—Ç –Ω–∏ token, –Ω–∏ signed_url –≤ –æ—Ç–≤–µ—Ç–µ');
      }

      // 4. Send menu context
      if (!contextSent.current) {
        setTimeout(() => {
          try {
            conversation.sendContextualUpdate(buildMenuContext());
            contextSent.current = true;
            console.log('[ElevenLabs] Menu context sent');
          } catch (e) {
            console.error('[ElevenLabs] Failed to send context:', e);
          }
        }, 1000);
      }
    } catch (e: any) {
      console.error('[ElevenLabs] Start error:', e);
      setError(e.message || '–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è');
      updateDebug({ session: 'failed', lastError: e.message || 'Unknown' });
    } finally {
      setIsConnecting(false);
    }
  }, [conversation, updateDebug]);

  const stop = useCallback(async () => {
    await conversation.endSession();
    setTranscript('');
    setAgentText('');
  }, [conversation]);

  const isActive = conversation.status === 'connected';

  const statusDisplay = () => {
    if (isConnecting) return { text: '–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...', color: 'text-yellow-600' };
    if (!isActive) return null;
    if (conversation.isSpeaking) return { text: 'üîä Speaking ‚Äî –∞–≥–µ–Ω—Ç –≥–æ–≤–æ—Ä–∏—Ç', color: 'text-primary' };
    return { text: 'üé§ Listening ‚Äî –≥–æ–≤–æ—Ä–∏—Ç–µ...', color: 'text-green-600' };
  };

  const status = statusDisplay();

  return (
    <>
      <div className="glass-card rounded-2xl p-5">
        <div className="flex items-center justify-between mb-4">
          <h3 className="font-display text-lg font-semibold">üéô –ì–æ–ª–æ—Å–æ–º</h3>
          <div className="flex items-center gap-2">
            <button
              onClick={() => setShowDebug(!showDebug)}
              className="p-1.5 rounded-lg hover:bg-secondary text-muted-foreground"
              title="Debug –ø–∞–Ω–µ–ª—å"
            >
              <Bug className="w-4 h-4" />
            </button>
            <span className={`text-xs font-medium px-2.5 py-1 rounded-full ${
              isActive ? 'bg-green-100 text-green-700' : 'bg-secondary text-muted-foreground'
            }`}>
              {isConnecting ? '–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...' : isActive ? '–ü–æ–¥–∫–ª—é—á—ë–Ω' : '–û—Ç–∫–ª—é—á—ë–Ω'}
            </span>
          </div>
        </div>

        {error && <p className="text-sm text-destructive mb-3 bg-destructive/10 p-2 rounded-lg">{error}</p>}

        {/* Debug Panel */}
        <AnimatePresence>
          {showDebug && (
            <motion.div
              initial={{ opacity: 0, height: 0 }}
              animate={{ opacity: 1, height: 'auto' }}
              exit={{ opacity: 0, height: 0 }}
              className="mb-4 bg-secondary/50 rounded-xl p-3 text-xs font-mono space-y-1 border border-border/50"
            >
              <p className="font-semibold text-muted-foreground mb-1">üîß Debug Panel</p>
              <p>token: <span className={debug.token === 'OK' ? 'text-green-600' : debug.token === 'FAIL' ? 'text-destructive' : 'text-muted-foreground'}>{debug.token}</span></p>
              <p>signedUrl: <span className={debug.signedUrl === 'OK' ? 'text-green-600' : debug.signedUrl === 'FAIL' ? 'text-destructive' : 'text-muted-foreground'}>{debug.signedUrl}</span></p>
              <p>connectionType: <span className="text-primary">{debug.connectionType}</span></p>
              <p>micPermission: <span className={debug.micPermission === 'granted' ? 'text-green-600' : debug.micPermission === 'denied' ? 'text-destructive' : 'text-muted-foreground'}>{debug.micPermission}</span></p>
              <p>audioTracksCount: {debug.audioTracksCount}</p>
              <p>session: <span className={debug.session === 'started' ? 'text-green-600' : debug.session === 'failed' ? 'text-destructive' : 'text-muted-foreground'}>{debug.session}</span></p>
              <p>status (SDK): {conversation.status}</p>
              <p>isSpeaking: {String(conversation.isSpeaking)}</p>
              <p>lastEventType: {debug.lastEventType || '‚Äî'}</p>
              {debug.lastError && <p>lastError: <span className="text-destructive">{debug.lastError}</span></p>}
            </motion.div>
          )}
        </AnimatePresence>

        {/* Status indicator */}
        {isActive && status && (
          <div className={`flex items-center gap-2 text-sm mb-3 ${status.color}`}>
            {conversation.isSpeaking
              ? <Volume2 className="w-4 h-4 animate-pulse" />
              : <Mic className="w-4 h-4 animate-pulse" />
            }
            <span className="font-medium">{status.text}</span>
          </div>
        )}

        {/* Transcripts */}
        {isActive && (
          <AnimatePresence>
            <motion.div initial={{ opacity: 0 }} animate={{ opacity: 1 }} className="space-y-3 mb-4">
              {transcript && (
                <div className="bg-secondary rounded-xl p-3">
                  <p className="text-xs text-muted-foreground mb-1">–í—ã —Å–∫–∞–∑–∞–ª–∏:</p>
                  <p className="text-sm">{transcript}</p>
                </div>
              )}
              {agentText && (
                <div className="bg-primary/5 rounded-xl p-3 border border-primary/10">
                  <p className="text-xs text-primary mb-1">–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç:</p>
                  <p className="text-sm">{agentText.replace(/<UI_ACTION>[\s\S]*?<\/UI_ACTION>/g, '').trim()}</p>
                </div>
              )}
            </motion.div>
          </AnimatePresence>
        )}

        <button
          onClick={isActive ? stop : start}
          disabled={isConnecting}
          className={`w-full flex items-center justify-center gap-2 py-3 rounded-xl font-semibold text-sm transition-all duration-300 ${
            isActive
              ? 'bg-destructive/10 text-destructive hover:bg-destructive/20'
              : 'gradient-primary text-primary-foreground hover:shadow-lg hover:shadow-primary/20'
          } disabled:opacity-50`}
        >
          {isActive ? <><MicOff className="w-4 h-4" /> –°—Ç–æ–ø</> : <><Mic className="w-4 h-4" /> {isConnecting ? '–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...' : '–ù–∞—á–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä'}</>}
        </button>
      </div>

      <MenuPickerModal payload={pickerPayload} onClose={() => setPickerPayload(null)} />
    </>
  );
};

export default VoiceAssistant;
